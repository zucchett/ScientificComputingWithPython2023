{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "1\\. **Text files**\n\nPerform the following operations on plain `txt` files:\n\n+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n+ load the `txt` file of the previous point and convert it to a `csv` file by hand.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Operation 1: Creating a list of integer numbers\ninteger_numbers = [1, 2, 3, 4, 5]\nwith open(\"data_int.txt\", \"w\") as file:\n    for number in integer_numbers:\n        file.write(str(number) + \"\\n\")\nprint(\"Integer numbers have been saved to data_int.txt. Here's what it looks like:\")\n# Now, let's print the content of the file using the cat command\n!cat data_int.txt\n\n# Operation 2: Creating a matrix of 5x5 floats\nmatrix = [[0.1, 0.2, 0.3, 0.4, 0.5],\n          [0.6, 0.7, 0.8, 0.9, 1.0],\n          [1.1, 1.2, 1.3, 1.4, 1.5],\n          [1.6, 1.7, 1.8, 1.9, 2.0],\n          [2.1, 2.2, 2.3, 2.4, 2.5]]\nwith open(\"data_float.txt\", \"w\") as file:\n    for row in matrix:\n        file.write(\" \".join([str(num) for num in row]) + \"\\n\")\nprint(\"Float matrix has been saved to data_float.txt. Here's what it looks like:\")\n# Let's print the content of the file using the cat command once again\n!cat data_float.txt\n\n# Operation 3: Converting the float matrix to a CSV file\nimport csv\n\n# First, load the text file\nloaded_matrix = []\nwith open(\"data_float.txt\", \"r\") as file:\n    for line in file:\n        loaded_matrix.append([float(num) for num in line.strip().split()])\n\n# Now, let's convert it to a CSV file\nwith open(\"data_float.csv\", \"w\", newline=\"\") as file:\n    writer = csv.writer(file)\n    for row in loaded_matrix:\n        writer.writerow(row)\nprint(\"The float matrix has been converted to data_float.csv\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "2\\. **JSON files**\n\nLoad the file `user_data.json`, which can be found at:\n\n- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n\nand filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import json\nimport csv\n\nfilename = \"filtered_data.csv\"\n\n# Fetch and load the JSON data\nwith open(\"user_data.json\", \"r\") as file:\n    data = json.load(file)\n\n# Filter the data based on the \"CreditCardType\" field\nfiltered_data = [user for user in data if user.get(\"CreditCardType\") == \"American Express\"]\n\n# Save the filtered data to a CSV file\nwith open(filename, \"w\", newline=\"\") as file:\n    writer = csv.DictWriter(file, fieldnames=filtered_data[0].keys())\n    writer.writeheader()\n    writer.writerows(filtered_data)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "3\\. **CSV files with Pandas**\n\nLoad the file from this url:\n\n- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n\nwith Pandas. \n\n+ explore and print the DataFrame\n+ calculate, using `groupby()`, the average value of each feature, separately for each class\n+ save the file in a JSON format.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\n# Load the mushrooms_categorized.csv file into a DataFrame\ndata = pd.read_csv(\"mushrooms_categorized.csv\")\n\n# Explore and print the DataFrame\nprint(data)\n\n# Calculate the average value of each feature, separately for each class using groupby()\naverages = data.groupby(\"class\").mean()\n\n# Save the DataFrame with average values to a JSON file\naverages.to_json(\"averages.json\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "4\\. **Reading a database**\n\nGet the database `sakila.db` from the lecture `06_dataio.ipynb`, and import the table `actors` as a Pandas dataframe. Using the dataframe, count how many actors have a first name that begins with `A`.\n\n*Hint:* use the Series `.str` method to apply the Python string methods to the elements of a Series, see [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport sqlite3\n\n# Connect to the sakila.db database\nconn = sqlite3.connect(\"dat/sakila.db\")\n\n# Import the 'actors' table as a Pandas DataFrame\nquery = \"SELECT * FROM actor\"\nactors_df = pd.read_sql_query(query, conn)\n\n# Count how many actors have a first name that begins with 'A'\ncount_actors_with_a = actors_df[actors_df['first_name'].str.startswith('A')].shape[0]\n\n# Display the count\nprint(f\"The number of actors with a first name starting with 'A' is: {count_actors_with_a}\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "5\\. **Reading the credit card numbers**\n\nGet the binary file named `credit_card.dat` from this address:\n\n- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n\nand convert the data into the real credit card number, knowing that:\n- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n- each character is written using a 6 bit binary representation (including the whitespace)\n- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n\n*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Open the binary file in read mode\nwith open(\"credit_card.dat\", \"rb\") as file:\n    # Read the binary data from the file\n    binary_data = file.read().decode()\n\n# Split the binary data into lines\nlines = binary_data.splitlines()\n\n# Convert each line to the real credit card number\ncredit_cards = []\nfor line in lines:\n    # Remove the padding bits at the end of each line\n    line = line[:-4]\n    \n    # Split the line into 4 blocks\n    blocks = [line[i:i+6] for i in range(0, len(line), 6)]\n    \n    # Convert each block from binary to decimal and then to a character\n    card_number = ''.join([chr(int(block, 2)) for block in blocks])\n    \n    # Add the credit card number to the list\n    credit_cards.append(card_number)\n\n# Print the converted credit card numbers\nfor card in credit_cards:\n    print(card)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "6\\. **Write data to a binary file**\n\na) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from IPython.display import Image\nImage(\"images/data_format.png\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "*Hints*:\n- Read the first 10 lines using Pandas\n- Iterate over the DataFrame rows\n- For every row, \"pack\" the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n- Write each 64-bit word to a binary file. You can use `struct` in this way:\n```\nbinary_file.write( struct.pack('<q', word) )\n```\nwhere `word` is the 64-bit word.\n- Close the file after completing the loop.\n\nb) Check that the binary file is correctly written by reading it with the code used in the lecture `06_dataio.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n\nc) What is the difference of the size on disk between equivalent `txt` and binary files?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport struct\n\n# Read the first 10 lines using Pandas\ndf = pd.read_csv('data/data_000637.txt', sep=',', nrows=10)\n\n# Open a binary file to write the converted data\nwith open('data/data_000637.dat', 'wb') as binary_file:\n    # Iterate over the DataFrame rows\n    for _, row in df.iterrows():\n        # Extract the values from the row\n        head = row['HEAD']\n        fpga = row['FPGA']\n        tdc_chan = row['TDC_CHANNEL']\n        orb_cnt = row['ORBIT_CNT']\n        bx = row['BX_COUNTER']\n        tdc_meas = row['TDC_MEAS']\n        \n        # Pack the values into a single 64-bit word\n        word = (head << 62) | (fpga << 58) | (tdc_chan << 49) | (orb_cnt << 17) | (bx << 5) | tdc_meas\n        \n        # Write the 64-bit word to the binary file\n        binary_file.write(struct.pack('<q', word))\n\n# Close the binary file after completing the loop\nbinary_file.close()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# It works and the data is consistent\n# but first of all I cannot understand what does that have to do with a PNG file (?!?!?)\n# and second it is impossible to compare txt and binary files since I wrote only ten lines in it",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}