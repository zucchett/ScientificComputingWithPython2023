{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Spotting correlations**\n",
    "\n",
    "Load the remote file:\n",
    "\n",
    "```bash\n",
    "https://www.dropbox.com/s/aamg1apjhclecka/regression_generated.csv\n",
    "```\n",
    "\n",
    "with Pandas and create scatter plots with all possible combinations of the following features:\n",
    "    \n",
    "  + `features_1`\n",
    "  + `features_2`\n",
    "  + `features_3`\n",
    "  \n",
    "Are these features correlated? Please add a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the file\n",
    "data = pd.read_csv('regression_generated.csv')\n",
    "\n",
    "# Features to plot\n",
    "features = ['features_1', 'features_2', 'features_3']\n",
    "\n",
    "# Create scatter plots\n",
    "for i in range(len(features)):\n",
    "    for j in range(i+1, len(features)):\n",
    "        plt.scatter(data[features[i]], data[features[j]])\n",
    "        plt.xlabel(features[i])\n",
    "        plt.ylabel(features[j])\n",
    "        plt.show()\n",
    "\n",
    "# Check correlation between features\n",
    "correlation = data[features].corr()\n",
    "print(correlation)\n",
    "\n",
    "# The correlation matrix indicates low correlation between the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **Color-coded scatter plot**\n",
    "\n",
    "Produce a scatter plot from a dataset with two categories.\n",
    "\n",
    "* Write a function that generates a 2D dataset consisting of 2 categories. Each category should distribute as a 2D gaussian with a given mean and standard deviation. Set different values of the mean and standard deviation between the two samples.\n",
    "* Display the dataset in a scatter plot marking the two categories with different marker colors.\n",
    "\n",
    "An example is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('images/two_categories_scatter_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_dataset(mean1, mean2, std1, std2, size):\n",
    "    # Generate data for category 1\n",
    "    category1 = np.random.multivariate_normal(mean1, std1, size)\n",
    "    \n",
    "    # Generate data for category 2\n",
    "    category2 = np.random.multivariate_normal(mean2, std2, size)\n",
    "    \n",
    "    # Combine the categories\n",
    "    dataset = np.concatenate((category1, category2))\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Set the parameters for the dataset\n",
    "mean1 = [2, 3]  # Mean of category 1\n",
    "mean2 = [-1, -2]  # Mean of category 2\n",
    "std1 = [[0.5, 0], [0, 0.5]]  # Standard deviation of category 1\n",
    "std2 = [[1, 0], [0, 1]]  # Standard deviation of category 2\n",
    "size = 100  # Size of each category\n",
    "\n",
    "# Generate the dataset\n",
    "dataset = generate_dataset(mean1, mean2, std1, std2, size)\n",
    "\n",
    "# Separate the categories\n",
    "category1 = dataset[:size]\n",
    "category2 = dataset[size:]\n",
    "\n",
    "# Plot the dataset\n",
    "plt.scatter(category1[:, 0], category1[:, 1], color='blue', label='Category 1')\n",
    "plt.scatter(category2[:, 0], category2[:, 1], color='red', label='Category 2')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **Profile plot**\n",
    "\n",
    "Produce a profile plot from a scatter plot.\n",
    "* Download the following pickle file:\n",
    "```bash\n",
    "wget https://www.dropbox.com/s/3uqleyc3wyz52tr/residuals_261.pkl -P data/\n",
    "```\n",
    "* Inspect the dataset, you'll find two variables (features)\n",
    "* Convert the content to a Pandas Dataframe\n",
    "* Clean the sample by selecting the entries (rows) with the absolute values of the variable \"residual\" smaller than 2\n",
    "* Plot a Seaborn `jointplot` of \"residuals\" versus \"distances\", and use seaborn to display a linear regression. \n",
    "\n",
    "Comment on the correlation between these variables.\n",
    "\n",
    "* Create manually (without using seaborn) the profile histogram for the \"distance\" variable; choose an appropriate binning.\n",
    "* Obtain 3 numpy arrays:\n",
    "  * `x`, the array of bin centers of the profile histogram of the \"distance\" variable\n",
    "  * `y`, the mean values of the \"residuals\", estimated in slices (bins) of \"distance\"\n",
    "  * `err_y`, the standard deviation of the of the \"residuals\", estimated in slices (bins) of \"distance\"\n",
    "* Plot the profile plot on top of the scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Inspect the dataset and convert to a Pandas DataFrame\n",
    "with open('data/residuals_261.pkl', \"rb\") as file:\n",
    "    data = pickle.load(file).item()\n",
    "\n",
    "dataFrame = pd.DataFrame({\"residuals\": data[\"residuals\"], \"distances\": data[\"distances\"]})\n",
    "print(dataFrame)\n",
    "\n",
    "# Step 2: Clean the sample by selecting entries with absolute values of \"residual\" < 2\n",
    "clean_data = dataFrame[abs(dataFrame['residuals']) < 2]\n",
    "\n",
    "# Step 3: Plot a Seaborn jointplot of \"residuals\" versus \"distances\" with linear regression\n",
    "sns.jointplot(data=clean_data, x='distances', y='residuals', kind='reg')\n",
    "\n",
    "# Step 4: Comment on the correlation between the variables\n",
    "correlation = clean_data['distances'].corr(clean_data['residuals'])\n",
    "print(\"The correlation between distances and residuals is:\", correlation)\n",
    "\n",
    "# Step 5: Create the profile histogram manually\n",
    "bin_width = 10  # Choose an appropriate bin width\n",
    "bins = np.arange(min(clean_data['distances']), max(clean_data['distances']) + bin_width, bin_width)\n",
    "x = bins[:-1] + bin_width / 2\n",
    "y = []\n",
    "err_y = []\n",
    "\n",
    "for i in range(len(bins) - 1):\n",
    "    bin_entries = clean_data[(clean_data['distances'] >= bins[i]) & (clean_data['distances'] < bins[i+1])]\n",
    "    y.append(bin_entries['residuals'].mean())\n",
    "    err_y.append(bin_entries['residuals'].std())\n",
    "\n",
    "# Step 6: Plot the profile plot on top of the scatter plot\n",
    "plt.scatter(clean_data['distances'], clean_data['residuals'], label='Scatter Plot')\n",
    "plt.errorbar(x, y, yerr=err_y, color='red', label='Profile Plot')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Kernel Density Estimate**\n",
    "\n",
    "Produce a KDE for a given distribution (by hand, not using seaborn):\n",
    "\n",
    "* Fill a numpy array `x` of length N (with $N=\\mathcal{O}(100)$) with a variable normally distributed, with a given mean and standard deviation\n",
    "* Fill an histogram in pyplot taking proper care of the aesthetic:\n",
    "   * use a meaningful number of bins\n",
    "   * set a proper y axis label\n",
    "   * set proper value of y axis major ticks labels (e.g. you want to display only integer labels)\n",
    "   * display the histograms as data points with errors (the error being the poisson uncertainty)\n",
    "* For every element of `x`, create a gaussian with the mean corresponding to the element value and the standard deviation as a parameter that can be tuned. The standard deviation default value should be:\n",
    "$$ 1.06 * x.std() * x.size ^{-\\frac{1}{5}} $$\n",
    "you can use the scipy function `stats.norm()` for that.\n",
    "* In a separate plot (to be placed beside the original histogram), plot all the gaussian functions so obtained\n",
    "* Sum (with `np.sum()`) all the gaussian functions and normalize the result such that the integral matches the integral of the original histogram. For that you could use the `scipy.integrate.trapz()` method. Superimpose the normalized sum of all gaussians to the first histogram.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, integrate\n",
    "\n",
    "# Define function to create the Kernel Density Estimate (KDE)\n",
    "def create_kde(x, mean, std):\n",
    "    kernel = stats.norm(mean, std)\n",
    "    return kernel.pdf(x)\n",
    "\n",
    "# Generate numpy array 'x' with normally distributed values\n",
    "N = 100\n",
    "mean = 0  # Set your desired mean\n",
    "std = 1  # Set your desired standard deviation\n",
    "x = np.random.normal(mean, std, N)\n",
    "\n",
    "# Plotting the histogram and KDE\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "\n",
    "# Plotting the histogram as data points with errors\n",
    "counts, bins, _ = axes[0].hist(x, bins='auto', alpha=0.7, color='purple')\n",
    "bin_centers = 0.5 * (bins[1:] + bins[:-1])\n",
    "bin_width = bins[1] - bins[0]\n",
    "errors = np.sqrt(counts)  # Poisson uncertainty\n",
    "axes[0].errorbar(bin_centers, counts, yerr=errors, fmt='o', color='black')\n",
    "axes[0].set_ylabel('Counts')\n",
    "axes[0].yaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "axes[0].set_xlabel('x')\n",
    "\n",
    "# Plotting the KDE\n",
    "kde_sum = np.zeros_like(x)\n",
    "std_tuned = 1.06 * x.std() * x.size**(-1/5)\n",
    "for point in x:\n",
    "    kde = create_kde(x, point, std_tuned)\n",
    "    kde_sum += kde\n",
    "    axes[1].plot(x, kde, alpha=0.3, color='green')\n",
    "\n",
    "# Normalize the sum of KDEs\n",
    "kde_sum /= integrate.trapz(kde_sum, x)\n",
    "axes[0].plot(x, kde_sum, color='red', linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
