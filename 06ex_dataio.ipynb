{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[[0.94333551 0.35266247 0.64604252 0.40206234 0.65691699]\n",
      " [0.17963127 0.40246172 0.01233075 0.51604961 0.54024938]\n",
      " [0.26897492 0.58530442 0.76454524 0.2310344  0.50324465]\n",
      " [0.53197627 0.27998464 0.36723576 0.71255295 0.20372136]\n",
      " [0.93397753 0.14773583 0.06956368 0.00848783 0.98506001]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "data\\data_float.txt\n",
      "\n",
      "\n",
      "Impossibile trovare il file specificato.\n",
      "Errore occorso durante l'elaborazione: #equivalente.\n",
      "Impossibile trovare il file specificato.\n",
      "Errore occorso durante l'elaborazione: di.\n",
      "Impossibile trovare il file specificato.\n",
      "Errore occorso durante l'elaborazione: cat.\n"
     ]
    }
   ],
   "source": [
    "l=[1,2,3,4]\n",
    "f=open('data/data_int.txt', 'w')\n",
    "f.write(str(l))\n",
    "f.close()\n",
    "#!cat data_int.txt\n",
    "!type data\\data_int.txt\n",
    "import numpy.random as npr\n",
    "m=npr.rand(5, 5)\n",
    "g=open('data/data_float.txt','w')\n",
    "g.write(str(m))\n",
    "g.close()\n",
    "#!cat data_int.txt\n",
    "!type data\\data_float.txt #equivalente di cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "read_file = pd.read_csv ('data\\data_float.txt')\n",
    "read_file.to_csv ('data\\data_float.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file `user_data.json`, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ID': '2', 'JobTitle': 'Investment  Advisor', 'EmailAddress': 'Clint_Thorpe5003@bulaffy.com', 'FirstNameLastName': 'Clint Thorpe', 'CreditCard': '7083-8766-0251-2345', 'CreditCardType': 'American Express'}\n",
      "{'ID': '12', 'JobTitle': 'Retail Trainee', 'EmailAddress': 'Phillip_Carpenter9505@famism.biz', 'FirstNameLastName': 'Phillip Carpenter', 'CreditCard': '3657-0088-0820-5247', 'CreditCardType': 'American Express'}\n",
      "{'ID': '28', 'JobTitle': 'Project Manager', 'EmailAddress': 'Russel_Graves1378@extex.org', 'FirstNameLastName': 'Russel Graves', 'CreditCard': '6718-4818-8011-6024', 'CreditCardType': 'American Express'}\n",
      "{'ID': '39', 'JobTitle': 'Stockbroker', 'EmailAddress': 'Leanne_Newton1268@typill.biz', 'FirstNameLastName': 'Leanne Newton', 'CreditCard': '5438-0816-4166-4847', 'CreditCardType': 'American Express'}\n",
      "{'ID': '57', 'JobTitle': 'Budget Analyst', 'EmailAddress': 'Tony_Giles1960@iatim.tech', 'FirstNameLastName': 'Tony Giles', 'CreditCard': '8130-3425-7573-7745', 'CreditCardType': 'American Express'}\n",
      "{'ID': '62', 'JobTitle': 'CNC Operator', 'EmailAddress': 'Owen_Allcott5125@bauros.biz', 'FirstNameLastName': 'Owen Allcott', 'CreditCard': '4156-0107-7210-2630', 'CreditCardType': 'American Express'}\n",
      "{'ID': '68', 'JobTitle': 'Project Manager', 'EmailAddress': 'Liam_Lynn3280@kideod.biz', 'FirstNameLastName': 'Liam Lynn', 'CreditCard': '7152-3247-6053-2233', 'CreditCardType': 'American Express'}\n",
      "{'ID': '74', 'JobTitle': 'Dentist', 'EmailAddress': 'Regina_Woodcock5820@yahoo.com', 'FirstNameLastName': 'Regina Woodcock', 'CreditCard': '0208-1753-3870-8002', 'CreditCardType': 'American Express'}\n",
      "{'ID': '81', 'JobTitle': 'HR Specialist', 'EmailAddress': 'Carter_Wallace9614@atink.com', 'FirstNameLastName': 'Carter Wallace', 'CreditCard': '4256-7201-6717-4322', 'CreditCardType': 'American Express'}\n",
      "{'ID': '92', 'JobTitle': 'Staffing Consultant', 'EmailAddress': 'Maia_Stark2797@jiman.org', 'FirstNameLastName': 'Maia Stark', 'CreditCard': '3851-1403-1734-6321', 'CreditCardType': 'American Express'}\n",
      "{'ID': '97', 'JobTitle': 'Stockbroker', 'EmailAddress': 'Ciara_Lomax982@bauros.biz', 'FirstNameLastName': 'Ciara Lomax', 'CreditCard': '3702-3440-2472-5424', 'CreditCardType': 'American Express'}\n",
      "{'ID': '116', 'JobTitle': 'Staffing Consultant', 'EmailAddress': 'Isabel_Ellwood1475@fuliss.net', 'FirstNameLastName': 'Isabel Ellwood', 'CreditCard': '3738-0882-0066-6683', 'CreditCardType': 'American Express'}\n",
      "{'ID': '148', 'JobTitle': 'CNC Operator', 'EmailAddress': 'Abdul_Townend2202@infotech44.tech', 'FirstNameLastName': 'Abdul Townend', 'CreditCard': '4224-1226-3557-3448', 'CreditCardType': 'American Express'}\n",
      "{'ID': '150', 'JobTitle': 'Fabricator', 'EmailAddress': 'Caleb_Poulton1735@atink.com', 'FirstNameLastName': 'Caleb Poulton', 'CreditCard': '8203-6875-5225-0341', 'CreditCardType': 'American Express'}\n",
      "{'ID': '151', 'JobTitle': 'Restaurant Manager', 'EmailAddress': 'Ronald_Lewis6777@deavo.com', 'FirstNameLastName': 'Ronald Lewis', 'CreditCard': '7212-0155-5014-8471', 'CreditCardType': 'American Express'}\n",
      "{'ID': '154', 'JobTitle': 'Bellman', 'EmailAddress': 'Faith_Seymour3829@twace.org', 'FirstNameLastName': 'Faith Seymour', 'CreditCard': '4170-5186-6887-6558', 'CreditCardType': 'American Express'}\n",
      "{'ID': '169', 'JobTitle': 'Assistant Buyer', 'EmailAddress': 'Anthony_Hancock9083@qater.org', 'FirstNameLastName': 'Anthony Hancock', 'CreditCard': '0832-3357-6010-6550', 'CreditCardType': 'American Express'}\n",
      "{'ID': '176', 'JobTitle': 'Healthcare Specialist', 'EmailAddress': 'Isabella_Willson5478@nanoff.biz', 'FirstNameLastName': 'Isabella Willson', 'CreditCard': '5177-4868-4623-0384', 'CreditCardType': 'American Express'}\n",
      "{'ID': '182', 'JobTitle': 'Pharmacist', 'EmailAddress': 'Stephanie_Darcy3298@bauros.biz', 'FirstNameLastName': 'Stephanie Darcy', 'CreditCard': '0264-4020-5106-5576', 'CreditCardType': 'American Express'}\n",
      "{'ID': '199', 'JobTitle': 'Investment  Advisor', 'EmailAddress': 'Ryan_Kennedy5565@corti.com', 'FirstNameLastName': 'Ryan Kennedy', 'CreditCard': '3166-6287-6242-7207', 'CreditCardType': 'American Express'}\n"
     ]
    }
   ],
   "source": [
    "import json # import the JSON module\n",
    "data = json.load(open('data/user_data.json'))\n",
    "f=open('data/use_data_AE.txt', 'w')\n",
    "#print(data)\n",
    "for i in range(len(data)):\n",
    "    if data[i]['CreditCardType']=='American Express':\n",
    "        print(data[i])\n",
    "        f.write(str(data[i]))\n",
    "f.close()        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      class  cap-shape  cap-surface  cap-color  bruises  odor  \\\n",
      "0         1          5            2          4        1     6   \n",
      "1         0          5            2          9        1     0   \n",
      "2         0          0            2          8        1     3   \n",
      "3         1          5            3          8        1     6   \n",
      "4         0          5            2          3        0     5   \n",
      "...     ...        ...          ...        ...      ...   ...   \n",
      "8119      0          3            2          4        0     5   \n",
      "8120      0          5            2          4        0     5   \n",
      "8121      0          2            2          4        0     5   \n",
      "8122      1          3            3          4        0     8   \n",
      "8123      0          5            2          4        0     5   \n",
      "\n",
      "      gill-attachment  gill-spacing  gill-size  gill-color  ...  \\\n",
      "0                   1             0          1           4  ...   \n",
      "1                   1             0          0           4  ...   \n",
      "2                   1             0          0           5  ...   \n",
      "3                   1             0          1           5  ...   \n",
      "4                   1             1          0           4  ...   \n",
      "...               ...           ...        ...         ...  ...   \n",
      "8119                0             0          0          11  ...   \n",
      "8120                0             0          0          11  ...   \n",
      "8121                0             0          0           5  ...   \n",
      "8122                1             0          1           0  ...   \n",
      "8123                0             0          0          11  ...   \n",
      "\n",
      "      stalk-surface-below-ring  stalk-color-above-ring  \\\n",
      "0                            2                       7   \n",
      "1                            2                       7   \n",
      "2                            2                       7   \n",
      "3                            2                       7   \n",
      "4                            2                       7   \n",
      "...                        ...                     ...   \n",
      "8119                         2                       5   \n",
      "8120                         2                       5   \n",
      "8121                         2                       5   \n",
      "8122                         1                       7   \n",
      "8123                         2                       5   \n",
      "\n",
      "      stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
      "0                          7          0           2            1          4   \n",
      "1                          7          0           2            1          4   \n",
      "2                          7          0           2            1          4   \n",
      "3                          7          0           2            1          4   \n",
      "4                          7          0           2            1          0   \n",
      "...                      ...        ...         ...          ...        ...   \n",
      "8119                       5          0           1            1          4   \n",
      "8120                       5          0           0            1          4   \n",
      "8121                       5          0           1            1          4   \n",
      "8122                       7          0           2            1          0   \n",
      "8123                       5          0           1            1          4   \n",
      "\n",
      "      spore-print-color  population  habitat  \n",
      "0                     2           3        5  \n",
      "1                     3           2        1  \n",
      "2                     3           2        3  \n",
      "3                     2           3        5  \n",
      "4                     3           0        1  \n",
      "...                 ...         ...      ...  \n",
      "8119                  0           1        2  \n",
      "8120                  0           4        2  \n",
      "8121                  0           1        2  \n",
      "8122                  7           4        2  \n",
      "8123                  4           1        2  \n",
      "\n",
      "[8124 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv ('data\\mushrooms_categorized.csv')\n",
    "print(df)\n",
    "c=df.groupby('class').mean()\n",
    "#print(c)\n",
    "c.to_json('data/mushrooms_categorized_n.json', orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading a database**\n",
    "\n",
    "Get the database `sakila.db` from the lecture `06_dataio.ipynb`, and import the table `actors` as a Pandas dataframe. Using the dataframe, count how many actors have a first name that begins with `A`.\n",
    "\n",
    "*Hint:* use the Series `.str` method to apply the Python string methods to the elements of a Series, see [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlite3.Cursor object at 0x000002D51A5F4140>\n",
      "       0         1             2                    3\n",
      "0      1  PENELOPE       GUINESS  2019-02-16 18:17:33\n",
      "1      2      NICK      WAHLBERG  2019-02-16 18:17:33\n",
      "2      3        ED         CHASE  2019-02-16 18:17:33\n",
      "3      4  JENNIFER         DAVIS  2019-02-16 18:17:33\n",
      "4      5    JOHNNY  LOLLOBRIGIDA  2019-02-16 18:17:33\n",
      "..   ...       ...           ...                  ...\n",
      "195  196      BELA        WALKEN  2019-02-16 18:17:33\n",
      "196  197     REESE          WEST  2019-02-16 18:17:33\n",
      "197  198      MARY        KEITEL  2019-02-16 18:17:33\n",
      "198  199     JULIA       FAWCETT  2019-02-16 18:17:33\n",
      "199  200     THORA        TEMPLE  2019-02-16 18:17:33\n",
      "\n",
      "[200 rows x 4 columns]\n",
      "Number of actors with a first name starting with 'A':  13\n"
     ]
    }
   ],
   "source": [
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "conn = sql.connect('data\\sakila.db')\n",
    "cur = conn.cursor()\n",
    "print(cur)\n",
    "query = \"SELECT * FROM actor;\"\n",
    "results = cur.execute(query).fetchall()\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "# Close the database connection\n",
    "\n",
    "# Count the actors with a first name that begins with 'A'\n",
    "countA = df[df[1].str.startswith('A')].shape[0]\n",
    "print(f\"Number of actors with a first name starting with 'A': \", countA)\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named `credit_card.dat` from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\laura\\ScientificComputingWithPython2023\\data/credit_card.dat\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'binary_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/credit_card.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     10\u001b[0m     line_data \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(binary_data)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m line_data:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line_data) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m118\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'binary_data' is not defined"
     ]
    }
   ],
   "source": [
    "import struct, time\n",
    "import os\n",
    "#hexdump(\"data/credit_card.dat\")io\n",
    "f=\"data/credit_card.dat\"\n",
    "script_dir = directory_path = os.getcwd()\n",
    "abs_file_path = os.path.join(script_dir, f)\n",
    "print(abs_file_path)\n",
    "creditcards = []\n",
    "with open(\"data/credit_card.dat\", \"rb\") as file:\n",
    "    line_data = file.readline()\n",
    "    print(binary_data)\n",
    "    while line_data:\n",
    "        if len(line_data) < 118:\n",
    "            break\n",
    "        creditcard = \"\"\n",
    "        for i in range(19):\n",
    "            substring = line_data[i * 6 + 2:i * 6 + 6]\n",
    "            if (i+1) % 5 == 0:\n",
    "                creditcard = creditcard + ' '\n",
    "            else:\n",
    "                digit = int(substring, base=2)\n",
    "            creditcard = creditcard + str(digit)\n",
    "        creditcards.append(creditcard)\n",
    "        line_data = file.readline()\n",
    "#for i in binary_data:\n",
    "#for i in range(0, len(binary_data), 6):\n",
    "    #word = struct.unpack('<q', binary_data[i : i + 6]+b'\\x00\\x00') # get an 8-byte word\n",
    "    #print(word)\n",
    "print(creditcards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/data_format.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, \"pack\" the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_dataio.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "import pandas as pd\n",
    "datatxt = pd.read_csv('data/data_000637.txt', nrows=10)\n",
    "#print(datatxt)\n",
    "#newfilerelativepath = \"data/data_000637_new.dat\"\n",
    "binary_file = open(\"data/data_000637_new.dat\", 'wb')\n",
    "for i in range(len(datatxt)):\n",
    "    word = ((datatxt.iloc[i, 0] & 0x3) << 62 |\n",
    "    (datatxt.iloc[i, 1] & 0xF) << 58 |\n",
    "    (datatxt.iloc[i, 2] & 0x1FF) << 49 |\n",
    "    (datatxt.iloc[i, 3] & 0xFFFFFFFF) << 17 |\n",
    "    (datatxt.iloc[i, 4] & 0xFFF) << 5 |\n",
    "    (datatxt.iloc[i, 5] & 0x1F))\n",
    "    binary_file.write( struct.pack('<q', word) )\n",
    "binary_file.close()\n",
    "data = {}\n",
    "columns = ['HEAD', 'FPGA', 'CHANNEL', 'ORBIT_CNT', 'BX_CNT', 'TDC_MEAS']\n",
    "df = pd.DataFrame({}, columns=columns)\n",
    "with open(\"data/data_000637_new.dat\", 'rb') as file:\n",
    "    file_content = file.read()\n",
    "    word_counter = 0\n",
    "    word_size = 8 # size of the word in bytes\n",
    "    for i in range(0, len(file_content), word_size):\n",
    "        word_counter += 1\n",
    "        if word_counter > 10: break\n",
    "        word = struct.unpack('<q', file_content[i : i + word_size])[0] # get an 8-byte word\n",
    "        head     = (word >> 62) & 0x3\n",
    "        fpga     = (word >> 58) & 0xF\n",
    "        tdc_chan = (word >> 49) & 0x1FF\n",
    "        orb_cnt  = (word >> 17) & 0xFFFFFFFF\n",
    "        bx       = (word >> 5 ) & 0xFFF\n",
    "        tdc_meas = (word >> 0 ) & 0x1F\n",
    "        #if i == 0: print ('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}'.format('HEAD', 'FPGA', 'CHANNEL', 'ORBIT_CNT', 'BX_CNT', 'TDC_MEAS'))\n",
    "        #print('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}'.format(head, fpga, tdc_chan, orb_cnt, bx, tdc_meas))\n",
    "        entry = {'HEAD' : head, 'FPGA' : fpga, 'CHANNEL' : tdc_chan, 'ORBIT_CNT' : orb_cnt, 'BX_CNT' : bx, 'TDC_MEAS' : tdc_meas}\n",
    "        #df = df.append(entry, ignore_index=True)\n",
    "        data[word_counter] = entry\n",
    "        \n",
    "df = pd.DataFrame(data).T\n",
    "df\n",
    "'''\n",
    "On average, each row in the text file consumes an additional 18 bytes compared to its counterpart in the\n",
    "binary packed dat file.This disparity arises from the encoding overhead (ASCII or Unicode) and the presence\n",
    "of additional characters, such as newline characters, in the text file. In contrast, the binary packed dat \n",
    "file is more space-efficient, resulting in a smaller size per row (8 bytes).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
