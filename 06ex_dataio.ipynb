{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "315ac8a7-b5fa-4688-9628-a017b99e22f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from data_int.txt:\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "\n",
      "Type integer data:\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "\n",
      "Data from data_float.txt:\n",
      "7.535909657488915059e-02 6.919304992106433128e-01 3.821943475921185662e-01 4.467055602625508159e-01 3.582200868864150456e-01\n",
      "2.920654923431069694e-01 9.736239003555452465e-01 1.857888510180223385e-01 6.595452623872910536e-01 5.798871006315131638e-01\n",
      "4.584047255487280204e-01 9.042076161367152976e-01 4.777491200555029627e-01 2.197638813317714934e-02 5.864161959797012935e-01\n",
      "2.881664171465829760e-01 9.300922027614934029e-01 5.614383120784293135e-01 2.783872505142852560e-01 1.285346641513631649e-01\n",
      "8.544744363735949921e-01 6.690486910919412056e-01 9.253389398434397339e-02 2.879751584037124612e-01 3.258251583256077666e-02\n",
      "\n",
      "Type float data:\n",
      "7.535909657488915059e-02 6.919304992106433128e-01 3.821943475921185662e-01 4.467055602625508159e-01 3.582200868864150456e-01\n",
      "2.920654923431069694e-01 9.736239003555452465e-01 1.857888510180223385e-01 6.595452623872910536e-01 5.798871006315131638e-01\n",
      "4.584047255487280204e-01 9.042076161367152976e-01 4.777491200555029627e-01 2.197638813317714934e-02 5.864161959797012935e-01\n",
      "2.881664171465829760e-01 9.300922027614934029e-01 5.614383120784293135e-01 2.783872505142852560e-01 1.285346641513631649e-01\n",
      "8.544744363735949921e-01 6.690486910919412056e-01 9.253389398434397339e-02 2.879751584037124612e-01 3.258251583256077666e-02\n",
      "\n",
      "Type CSV data:\n",
      "0.075359,0.691930,0.382194,0.446706,0.358220\n",
      "0.292065,0.973624,0.185789,0.659545,0.579887\n",
      "0.458405,0.904208,0.477749,0.021976,0.586416\n",
      "0.288166,0.930092,0.561438,0.278387,0.128535\n",
      "0.854474,0.669049,0.092534,0.287975,0.032583\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "int_matrix = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "np.savetxt(\"data_int.txt\", int_matrix, fmt='%d')  # Specify fmt='%d' for integers\n",
    "with open(\"data_int.txt\", 'r') as file_int:\n",
    "    data_int = file_int.read()\n",
    "print(\"Data from data_int.txt:\")\n",
    "print(data_int)\n",
    "\n",
    "print(\"Type integer data:\")\n",
    "# Display the content of the file using the 'type' command on Windows (The cat command is commonly used on Unix-like systems)\n",
    "!type data_int.txt\n",
    "\n",
    "float_matrix = np.random.rand(5, 5)\n",
    "np.savetxt(\"data_float.txt\", float_matrix)\n",
    "with open(\"data_float.txt\", 'r') as file_float:\n",
    "    data_float = file_float.read()\n",
    "print(\"\\nData from data_float.txt:\")\n",
    "print(data_float)\n",
    "\n",
    "print(\"Type float data:\")\n",
    "!type data_float.txt\n",
    "\n",
    "\n",
    "# Step 3: Load the text file and convert it to a CSV file\n",
    "loaded_data = np.loadtxt(\"data_float.txt\")\n",
    "np.savetxt(\"data_float.csv\", loaded_data, delimiter=\",\", fmt='%.6f')\n",
    "\n",
    "print(\"\\nType CSV data:\")\n",
    "!type data_float.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72bcf36f-c698-4522-97ad-0f3e816a198b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'list'>\n",
      "Keys: dict_keys(['ID', 'JobTitle', 'EmailAddress', 'FirstNameLastName', 'CreditCard', 'CreditCardType'])\n",
      "Number of Entries: 200\n",
      "Are there missing credit card values? False\n",
      "Filtered data saved to american_express_data.csv\n",
      "ID,JobTitle,EmailAddress,FirstNameLastName,CreditCard,CreditCardType\n",
      "2,Investment  Advisor,Clint_Thorpe5003@bulaffy.com,Clint Thorpe,7083-8766-0251-2345,American Express\n",
      "12,Retail Trainee,Phillip_Carpenter9505@famism.biz,Phillip Carpenter,3657-0088-0820-5247,American Express\n",
      "28,Project Manager,Russel_Graves1378@extex.org,Russel Graves,6718-4818-8011-6024,American Express\n",
      "39,Stockbroker,Leanne_Newton1268@typill.biz,Leanne Newton,5438-0816-4166-4847,American Express\n",
      "57,Budget Analyst,Tony_Giles1960@iatim.tech,Tony Giles,8130-3425-7573-7745,American Express\n",
      "62,CNC Operator,Owen_Allcott5125@bauros.biz,Owen Allcott,4156-0107-7210-2630,American Express\n",
      "68,Project Manager,Liam_Lynn3280@kideod.biz,Liam Lynn,7152-3247-6053-2233,American Express\n",
      "74,Dentist,Regina_Woodcock5820@yahoo.com,Regina Woodcock,0208-1753-3870-8002,American Express\n",
      "81,HR Specialist,Carter_Wallace9614@atink.com,Carter Wallace,4256-7201-6717-4322,American Express\n",
      "92,Staffing Consultant,Maia_Stark2797@jiman.org,Maia Stark,3851-1403-1734-6321,American Express\n",
      "97,Stockbroker,Ciara_Lomax982@bauros.biz,Ciara Lomax,3702-3440-2472-5424,American Express\n",
      "116,Staffing Consultant,Isabel_Ellwood1475@fuliss.net,Isabel Ellwood,3738-0882-0066-6683,American Express\n",
      "148,CNC Operator,Abdul_Townend2202@infotech44.tech,Abdul Townend,4224-1226-3557-3448,American Express\n",
      "150,Fabricator,Caleb_Poulton1735@atink.com,Caleb Poulton,8203-6875-5225-0341,American Express\n",
      "151,Restaurant Manager,Ronald_Lewis6777@deavo.com,Ronald Lewis,7212-0155-5014-8471,American Express\n",
      "154,Bellman,Faith_Seymour3829@twace.org,Faith Seymour,4170-5186-6887-6558,American Express\n",
      "169,Assistant Buyer,Anthony_Hancock9083@qater.org,Anthony Hancock,0832-3357-6010-6550,American Express\n",
      "176,Healthcare Specialist,Isabella_Willson5478@nanoff.biz,Isabella Willson,5177-4868-4623-0384,American Express\n",
      "182,Pharmacist,Stephanie_Darcy3298@bauros.biz,Stephanie Darcy,0264-4020-5106-5576,American Express\n",
      "199,Investment  Advisor,Ryan_Kennedy5565@corti.com,Ryan Kennedy,3166-6287-6242-7207,American Express\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "import json # import the JSON module\n",
    "data = json.load(open('user_data.json'))\n",
    "\n",
    "print(\"Type:\", type(data))  # Type: <class 'list'>\n",
    "print(\"Keys:\", data[0].keys())  # Keys: dict_keys(['ID', 'JobTitle', 'EmailAddress', 'FirstNameLastName', 'CreditCard', 'CreditCardType'])\n",
    "print(\"Number of Entries:\", len(data))  # 200\n",
    "\n",
    "# Check if there are any missing values for a specific attribute\n",
    "missing_credit_cards = any('CreditCard' not in entry for entry in data)\n",
    "print(\"Are there missing credit card values?\", missing_credit_cards)  # False\n",
    "\n",
    "\n",
    "# # Assuming 'CreditCardType' is an attribute, print all its values\n",
    "# credit_card_types = [entry['CreditCardType'] for entry in data]\n",
    "# print(\"Credit Card Types:\", credit_card_types)\n",
    "# # Print unique values for a specific attribute\n",
    "# unique_job_titles = set(entry['JobTitle'] for entry in data)\n",
    "# print(\"Unique Job Titles:\", unique_job_titles)\n",
    "\n",
    "\n",
    "# Filter data by \"CreditCardType\" equals to \"American Express\"\n",
    "filtered_data = [entry for entry in data if entry['CreditCardType'] == 'American Express']\n",
    "# credit_card_types2 = [entryy['CreditCardType'] for entryy in filtered_data]\n",
    "# print(\"Credit Card Types:\", credit_card_types2)  # All of them American Express\n",
    "\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "csv_file_path = 'american_express_data.csv'\n",
    "fields = filtered_data[0].keys()  # Assuming all entries have the same fields\n",
    "with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.DictWriter(csvfile, fieldnames=fields)\n",
    "    # Write the header\n",
    "    csv_writer.writeheader()  # shows columns names fieldnames'e göre sırayla\n",
    "    # Write the data\n",
    "    csv_writer.writerows(filtered_data)  \n",
    "\n",
    "print(f\"Filtered data saved to {csv_file_path}\")\n",
    "\n",
    "!type american_express_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b7b0721-c64f-4910-b2cc-b16e66cc0112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Values by Class:\n",
      "       cap-shape  cap-surface  cap-color   bruises      odor  gill-attachment  \\\n",
      "class                                                                           \n",
      "0       3.266160     1.615970   4.581749  0.653992  4.334601         0.954373   \n",
      "1       3.436159     2.055158   4.421859  0.159346  3.940756         0.995403   \n",
      "\n",
      "       gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
      "class                                                    ...   \n",
      "0          0.285171   0.068441    6.622624     0.615970  ...   \n",
      "1          0.028601   0.567926    2.863636     0.514811  ...   \n",
      "\n",
      "       stalk-surface-below-ring  stalk-color-above-ring  \\\n",
      "class                                                     \n",
      "0                      1.798479                6.098859   \n",
      "1                      1.394280                5.512768   \n",
      "\n",
      "       stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
      "class                                                                          \n",
      "0                    6.064639        0.0    1.931559     1.125475   3.007605   \n",
      "1                    5.504597        0.0    2.002043     1.009193   1.522983   \n",
      "\n",
      "       spore-print-color  population   habitat  \n",
      "class                                           \n",
      "0               3.201521    3.283270  1.148289  \n",
      "1               4.021450    4.031665  1.895812  \n",
      "\n",
      "[2 rows x 22 columns]\n",
      "\n",
      "DataFrame saved to mushrooms_average_values.json\n",
      "{\"cap-shape\":{\"0\":3.2661596958,\"1\":3.4361593463},\"cap-surface\":{\"0\":1.6159695817,\"1\":2.0551583248},\"cap-color\":{\"0\":4.5817490494,\"1\":4.4218590398},\"bruises\":{\"0\":0.6539923954,\"1\":0.1593462717},\"odor\":{\"0\":4.3346007605,\"1\":3.9407558733},\"gill-attachment\":{\"0\":0.9543726236,\"1\":0.9954034729},\"gill-spacing\":{\"0\":0.2851711027,\"1\":0.0286006129},\"gill-size\":{\"0\":0.0684410646,\"1\":0.5679264556},\"gill-color\":{\"0\":6.6226235741,\"1\":2.8636363636},\"stalk-shape\":{\"0\":0.6159695817,\"1\":0.5148110317},\"stalk-root\":{\"0\":1.4980988593,\"1\":0.6925434116},\"stalk-surface-above-ring\":{\"0\":1.7756653992,\"1\":1.3595505618},\"stalk-surface-below-ring\":{\"0\":1.7984790875,\"1\":1.3942798774},\"stalk-color-above-ring\":{\"0\":6.0988593156,\"1\":5.5127681307},\"stalk-color-below-ring\":{\"0\":6.0646387833,\"1\":5.5045965271},\"veil-type\":{\"0\":0.0,\"1\":0.0},\"veil-color\":{\"0\":1.9315589354,\"1\":2.0020429009},\"ring-number\":{\"0\":1.1254752852,\"1\":1.0091930541},\"ring-type\":{\"0\":3.0076045627,\"1\":1.5229826353},\"spore-print-color\":{\"0\":3.2015209125,\"1\":4.0214504597},\"population\":{\"0\":3.283269962,\"1\":4.0316649642},\"habitat\":{\"0\":1.1482889734,\"1\":1.8958120531}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import requests\n",
    "# url = \"https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\"\n",
    "# response = requests.get(url)\n",
    "# data = response.text\n",
    "# # Print the first 10 lines of the data\n",
    "# print('\\n'.join(data.split('\\n')[:10]))\n",
    "\n",
    "# Update Dropbox\n",
    "dropbox_url = \"https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\"\n",
    "direct_download_url = dropbox_url.replace(\"www.dropbox.com\", \"dl.dropboxusercontent.com\")\n",
    "# CSV dosyasını okuyun\n",
    "df = pd.read_csv(direct_download_url)\n",
    "#print(\"DataFrame:\")\n",
    "#print(df.head()) \n",
    "#print(df.columns)  # 23 column\n",
    "#print(df.dtypes)  # all int64\n",
    "\n",
    "# Calculate the average value of each feature, separately for each class using groupby\n",
    "average_by_class = df.groupby('class').mean()\n",
    "print(\"\\nAverage Values by Class:\")\n",
    "print(average_by_class)\n",
    "\n",
    "# Save the DataFrame to a JSON file\n",
    "json_file_path = 'mushrooms_average_values.json'\n",
    "average_by_class.to_json(json_file_path)\n",
    "print(f\"\\nDataFrame saved to {json_file_path}\")\n",
    "\n",
    "!type mushrooms_average_values.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4fdcd8d1-7cda-4e59-9e9e-b423c4935b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "\n",
    "# # create a connection to the database and a cursor to execute queries\n",
    "# conn = sql.connect('sakila.db')\n",
    "# cur = conn.cursor()\n",
    "# # query data from database: select all content from the table \"actor\"\n",
    "# query = \"SELECT * FROM actor\"\n",
    "# results = cur.execute(query).fetchall()\n",
    "# # create a DataFrame from the DB data\n",
    "# df = pd.DataFrame(results)\n",
    "# # close the cursor and connection\n",
    "# cur.close()\n",
    "# conn.close()\n",
    "\n",
    "# # create a connection to the database and a cursor to execute queries\n",
    "# conn = sql.connect('sakila.db')\n",
    "# # read the 'actors' table into a Pandas DataFrame\n",
    "# actors_df = pd.read_sql_query(\"SELECT * FROM actors\", conn)\n",
    "# # close the database connection\n",
    "# conn.close()\n",
    "# # count actors with first name starting with 'A'\n",
    "# actors_with_A_count = actors_df[actors_df['first_name'].str.startswith('A', na=False)].shape[0]\n",
    "# # print the result\n",
    "# print(f\"The number of actors with a first name starting with 'A' is: {actors_with_A_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218163df-e53c-49d0-b9b5-c4f591817c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51, 1)\n",
      "Length of row 0: 118\n",
      "Length of row 1: 118\n",
      "Length of row 8: 118\n",
      "Length of row 49: 118\n",
      "Length of row 50: 4\n",
      "Total character count: 5904\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"credit_card.dat\"\n",
    "data_df = pd.read_csv(file_path, sep='\\t', header=None)  # Use sep='\\t' if the file is tab-separated\n",
    "# print(data_df)\n",
    "\n",
    "print(data_df.shape)  # (51, 1)\n",
    "# #print(data_df.isnull().sum())  # 0\n",
    "\n",
    "selected_indices = [0, 1, 8, 49, 50]\n",
    "for index in selected_indices:\n",
    "    row = data_df.iloc[index, 0]\n",
    "    length = len(row)\n",
    "    print(f\"Length of row {index}: {length}\")  # All are 118\n",
    "total_character_count = 0\n",
    "for row in data_df.iloc[:, 0]:\n",
    "    total_character_count += len(row)\n",
    "print(f\"Total character count: {total_character_count}\")  # 5904\n",
    "\n",
    "data_df.iloc[:, 0] = data_df.iloc[:, 0].apply(lambda x: x[:-4])  # Each row became 114, last row removed, total of 50 rows now\n",
    "data_df.drop(50, inplace=True)\n",
    "\n",
    "# Update column name to \"credit_card\"\n",
    "data_df.columns = [\"credit_card\"]\n",
    "\n",
    "# space_count = data_df[0].apply(lambda x: x.count('1000001'))\n",
    "# total_space_count = space_count.sum()\n",
    "# print(f\"Total space count: {total_space_count}\")\n",
    "# data_df['has_three_spaces'] = space_count == 3\n",
    "# print(data_df[['has_three_spaces']])\n",
    "\n",
    "# # Convert binary numbers in each row to decimal numbers\n",
    "# data_df[\"credit_card\"] = data_df[\"credit_card\"].apply(lambda x: int(x[:-4], 2) if x[:] else None)\n",
    "\n",
    "# # Filter out NaN (Not a Number) values\n",
    "# data_df = data_df.dropna()\n",
    "# print(data_df)\n",
    "\n",
    "# Convert decimal numbers to characters and create the actual credit card number\n",
    "# data_df[\"real_credit_card\"] = data_df[\"decimal_numbers\"].apply(lambda x: ''.join([chr(int(x[i:i+6], 2)) for i in range(0, 24, 6)]))\n",
    "# data_df[\"real_credit_card\"] = data_df[\"decimal_numbers\"].apply(lambda x: ''.join([chr(int(str(x)[i:i+6], 2)) for i in range(0, 24, 6)]))\n",
    "\n",
    "# print(data_df[\"real_credit_card\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a2bc34a6-e388-47c6-85ff-bb0663129a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7648  567 3 37 75 2 271\n",
      "3257  824 7 33 54 2 266\n",
      "2722  000 1 40 11 6 652\n"
     ]
    }
   ],
   "source": [
    "# # Binary data\n",
    "# binary_data = \"\"\"\n",
    "# 1101111101101101001110001000001101011101101101111100111000001100111101111101111101011000001100101100101101111100011010\n",
    "# 1100111100101101011101111000001110001100101101001101111000001100111100111101011101001000001100101100101101101101101010\n",
    "# 1100101101111100101100101000001100001100001100001100011000001101001100001100011100011000001101101101101101011100101010\n",
    "# \"\"\"\n",
    "\n",
    "# # Split binary data into lines\n",
    "# lines = binary_data.strip().split('\\n')\n",
    "\n",
    "# # Convert binary to decimal and then to character\n",
    "# credit_cards = []\n",
    "# for line in lines:\n",
    "#     decimal_values = [int(line[i:i+6], 2) for i in range(0, len(line)-4, 6)]\n",
    "#     credit_card = ''.join(chr(value) for value in decimal_values)\n",
    "#     credit_cards.append(credit_card)\n",
    "\n",
    "# # Format the credit card numbers\n",
    "# formatted_credit_cards = []\n",
    "# for card in credit_cards:\n",
    "#     formatted_credit_card = ' '.join([card[i:i+4] for i in range(0, len(card), 4)])\n",
    "#     formatted_credit_cards.append(formatted_credit_card)\n",
    "\n",
    "# # Print the result\n",
    "# for card in formatted_credit_cards:\n",
    "#     print(card)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17e069c5-096d-42ad-b166-144609eaf588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd \n",
    "import struct\n",
    "\n",
    "# # Step a: Write data to a binary file\n",
    "# def txt_to_binary(input_txt, output_binary):\n",
    "#     # Read the first 10 lines using Pandas\n",
    "#     #df = pd.read_csv(input_txt, sep='\\t', nrows=10)\n",
    "#     df = pd.read_csv(input_txt, sep=',', nrows=10, header=None)\n",
    "#     # Add 'HEAD' as a column based on the index\n",
    "#     df['HEAD'] = df.index\n",
    "#     # Print column names to check\n",
    "#     print(\"Column names in the DataFrame:\", df.columns)\n",
    "#     # Open the binary file for writing\n",
    "#     with open(output_binary, 'wb') as binary_file:\n",
    "#         # Iterate over DataFrame rows\n",
    "#         for index, row in df.iterrows():\n",
    "#             # Print the row to check its structure\n",
    "#             print(\"Row:\", row)\n",
    "#             # Pack values into a single 64-bit word\n",
    "#             word = (int(row['HEAD']) << 48) | (int(row['FPGA']) << 40) | (int(row['TDC_CHANNEL']) << 32) | \\\n",
    "#                    (int(row['ORBIT_CNT']) << 0) | (int(row['BX_COUNTER']) << 16) | (int(row['TDC_MEAS']) << 8)\n",
    "#             # Write the 64-bit word to the binary file\n",
    "#             binary_file.write(struct.pack('<q', word))\n",
    "#     print(\"Binary file created successfully.\")\n",
    "\n",
    "# # Step b: Check the consistency by reading the binary file\n",
    "# def read_binary_and_compare(input_binary, input_txt):\n",
    "#     # Read the binary file\n",
    "#     with open(input_binary, 'rb') as binary_file:\n",
    "#         # Unpack 64-bit words and print them\n",
    "#         while True:\n",
    "#             data = binary_file.read(8)\n",
    "#             if not data:\n",
    "#                 break\n",
    "#             word = struct.unpack('<q', data)[0]\n",
    "#             print(f\"Read from binary: {word}\")\n",
    "#     # Read the txt file and compare\n",
    "#     df_txt = pd.read_csv(input_txt, sep='\\t', nrows=10)\n",
    "#     print(\"\\nContent of the txt file:\")\n",
    "#     print(df_txt)\n",
    "\n",
    "# # Step c: Calculate the size difference between txt and binary files\n",
    "# def compare_file_sizes(input_txt, input_binary):\n",
    "#     size_txt = pd.read_csv(input_txt, sep='\\t').memory_usage(index=False, deep=True).sum()\n",
    "#     size_binary = os.path.getsize(input_binary)\n",
    "#     print(f\"\\nSize of txt file on disk: {size_txt} bytes\")\n",
    "#     print(f\"Size of binary file on disk: {size_binary} bytes\")\n",
    "#     print(f\"Difference in size: {size_txt - size_binary} bytes\")\n",
    "\n",
    "# # Example usage\n",
    "# input_txt_file = 'data_000637.txt'\n",
    "# output_binary_file = 'data_000637.bin'\n",
    "# # Step a: Write data to a binary file\n",
    "# txt_to_binary(input_txt_file, output_binary_file)\n",
    "# # Step b: Check the consistency by reading the binary file\n",
    "# read_binary_and_compare(output_binary_file, input_txt_file)\n",
    "# # Step c: Calculate the size difference between txt and binary files\n",
    "# compare_file_sizes(input_txt_file, output_binary_file)\n",
    "\n",
    "# file_name = \"data_000637.txt\" \n",
    "# data = pd.read_csv(file_name) \n",
    "# df = data.head(10)\n",
    "# print(df)\n",
    "\n",
    "#Image(\"images/data_format.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58daa6c7-0abd-4e6a-abae-97dd84ee9b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
