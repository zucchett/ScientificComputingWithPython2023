{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is the list of integers used : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "Here's the data contained in the document displayed with cat\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# a.\n",
    "\n",
    "l_int = [i for i in range(11)]\n",
    "print(f\"\\nHere is the list of integers used : {l_int}\")\n",
    "\n",
    "# We write the different data in the text file\n",
    "with open('data_int.txt', 'w') as file:\n",
    "    for i in l_int:\n",
    "        file.write(f\"{i}\\n\")\n",
    "\n",
    "# Document content display\n",
    "print(\"\\nHere's the data contained in the document displayed with cat\\n\")\n",
    "!cat data_int.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is the matrix of float used : \n",
      "[[0.70722896 0.7319827  0.82627776 0.74467274 0.99803629]\n",
      " [0.85613476 0.8954037  0.12228441 0.29734591 0.50317787]\n",
      " [0.71643041 0.94353261 0.76893339 0.59758151 0.42884009]\n",
      " [0.39793235 0.2774773  0.1031978  0.24768914 0.02170648]\n",
      " [0.75017857 0.95863961 0.6404564  0.10300646 0.80544958]]\n",
      "\n",
      "Here's the data contained in the document displayed with cat\n",
      "\n",
      "0.7072289564219554 0.7319827004753666 0.8262777589767234 0.744672738662739 0.9980362930729886\n",
      "0.8561347637291286 0.8954037006161716 0.12228441123445988 0.29734590892489277 0.5031778709234682\n",
      "0.7164304080758693 0.9435326056446276 0.7689333874017799 0.5975815068537897 0.4288400864526234\n",
      "0.3979323530220594 0.2774773007809196 0.10319779601367318 0.24768914441023193 0.021706479220605424\n",
      "0.7501785723197045 0.9586396107114523 0.6404563964107242 0.10300646100724697 0.8054495791002674\n"
     ]
    }
   ],
   "source": [
    "# b.\n",
    "\n",
    "import numpy as np # import the NUMPY module\n",
    "\n",
    "m_float = np.random.rand(5, 5)\n",
    "print(f\"\\nHere is the matrix of float used : \\n{m_float}\")\n",
    "\n",
    "# We write the different data in the text file\n",
    "with open('data_float.txt', 'w') as file:\n",
    "    for row in m_float:\n",
    "        file_row = ' '.join(map(str, row))\n",
    "        file.write(file_row + '\\n')\n",
    "\n",
    "# Document content display\n",
    "print(\"\\nHere's the data contained in the document displayed with cat\\n\")\n",
    "!cat data_float.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here is the matrix of float loaded thanks to loadtxt : \n",
      "[[0.70722896 0.7319827  0.82627776 0.74467274 0.99803629]\n",
      " [0.85613476 0.8954037  0.12228441 0.29734591 0.50317787]\n",
      " [0.71643041 0.94353261 0.76893339 0.59758151 0.42884009]\n",
      " [0.39793235 0.2774773  0.1031978  0.24768914 0.02170648]\n",
      " [0.75017857 0.95863961 0.6404564  0.10300646 0.80544958]]\n",
      "\n",
      "Here's the data contained in the document displayed with cat\n",
      "\n",
      "matrix1;matrix2;matrix3;matrix4;matrix5\n",
      "0.7072289564219554;0.7319827004753666;0.8262777589767234;0.744672738662739;0.9980362930729886\n",
      "0.8561347637291286;0.8954037006161716;0.12228441123445988;0.29734590892489277;0.5031778709234682\n",
      "0.7164304080758693;0.9435326056446276;0.7689333874017799;0.5975815068537897;0.4288400864526234\n",
      "0.3979323530220594;0.2774773007809196;0.10319779601367318;0.24768914441023193;0.021706479220605424\n",
      "0.7501785723197045;0.9586396107114523;0.6404563964107242;0.10300646100724697;0.8054495791002674\n"
     ]
    }
   ],
   "source": [
    "# c.\n",
    "\n",
    "import pandas as pd # import the PANDAS module\n",
    "\n",
    "# Load data_float.txt\n",
    "m_float2 = np.loadtxt('data_float.txt')\n",
    "print(f\"\\nHere is the matrix of float loaded thanks to loadtxt : \\n{m_float}\")\n",
    "\n",
    "# Convert in dataframe\n",
    "df = pd.DataFrame(m_float2, columns = [\"matrix1\", \"matrix2\", \"matrix3\", \"matrix4\", \"matrix5\"])\n",
    "\n",
    "# We write the different data in the csv file\n",
    "with open('data_float.csv', 'w') as file:\n",
    "    header = ';'.join(map(str, df.columns))\n",
    "    file.write(header + '\\n')\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        line = ';'.join(map(str, row))\n",
    "        file.write(line + '\\n')\n",
    "\n",
    "# Document content display\n",
    "print(\"\\nHere's the data contained in the document displayed with cat\\n\")\n",
    "!cat data_float.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file `user_data.json`, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data before applying the filter :\n",
      "\n",
      "ID: 1, CreditCardType: Capital One\n",
      "ID: 2, CreditCardType: American Express\n",
      "ID: 3, CreditCardType: Discover\n",
      "ID: 4, CreditCardType: Discover\n",
      "ID: 5, CreditCardType: Citibank\n",
      "ID: 6, CreditCardType: MasterCard\n",
      "ID: 7, CreditCardType: MasterCard\n",
      "ID: 8, CreditCardType: Discover\n",
      "ID: 9, CreditCardType: Maestro\n",
      "ID: 10, CreditCardType: Bank of America\n",
      "ID: 11, CreditCardType: MasterCard\n",
      "ID: 12, CreditCardType: American Express\n",
      "ID: 13, CreditCardType: MasterCard\n",
      "ID: 14, CreditCardType: Maestro\n",
      "ID: 15, CreditCardType: Discover\n",
      "ID: 16, CreditCardType: Citibank\n",
      "ID: 17, CreditCardType: Maestro\n",
      "ID: 18, CreditCardType: Maestro\n",
      "ID: 19, CreditCardType: Chase\n",
      "ID: 20, CreditCardType: Discover\n",
      "ID: 21, CreditCardType: Visa\n",
      "ID: 22, CreditCardType: Citibank\n",
      "ID: 23, CreditCardType: UnionPay\n",
      "ID: 24, CreditCardType: UnionPay\n",
      "ID: 25, CreditCardType: Discover\n",
      "ID: 26, CreditCardType: Discover\n",
      "ID: 27, CreditCardType: Visa\n",
      "ID: 28, CreditCardType: American Express\n",
      "ID: 29, CreditCardType: UnionPay\n",
      "ID: 30, CreditCardType: Bank of America\n",
      "ID: 31, CreditCardType: Capital One\n",
      "ID: 32, CreditCardType: Maestro\n",
      "ID: 33, CreditCardType: Citibank\n",
      "ID: 34, CreditCardType: Chase\n",
      "ID: 35, CreditCardType: Citibank\n",
      "ID: 36, CreditCardType: Bank of America\n",
      "ID: 37, CreditCardType: Wells Fargo\n",
      "ID: 38, CreditCardType: MasterCard\n",
      "ID: 39, CreditCardType: American Express\n",
      "ID: 40, CreditCardType: Chase\n",
      "ID: 41, CreditCardType: Discover\n",
      "ID: 42, CreditCardType: Visa\n",
      "ID: 43, CreditCardType: Bank of America\n",
      "ID: 44, CreditCardType: UnionPay\n",
      "ID: 45, CreditCardType: Visa\n",
      "ID: 46, CreditCardType: Wells Fargo\n",
      "ID: 47, CreditCardType: Discover\n",
      "ID: 48, CreditCardType: Bank of America\n",
      "ID: 49, CreditCardType: Discover\n",
      "ID: 50, CreditCardType: Wells Fargo\n",
      "ID: 51, CreditCardType: MasterCard\n",
      "ID: 52, CreditCardType: Wells Fargo\n",
      "ID: 53, CreditCardType: UnionPay\n",
      "ID: 54, CreditCardType: Citibank\n",
      "ID: 55, CreditCardType: Discover\n",
      "ID: 56, CreditCardType: Visa\n",
      "ID: 57, CreditCardType: American Express\n",
      "ID: 58, CreditCardType: MasterCard\n",
      "ID: 59, CreditCardType: Discover\n",
      "ID: 60, CreditCardType: Citibank\n",
      "ID: 61, CreditCardType: Chase\n",
      "ID: 62, CreditCardType: American Express\n",
      "ID: 63, CreditCardType: MasterCard\n",
      "ID: 64, CreditCardType: Capital One\n",
      "ID: 65, CreditCardType: Capital One\n",
      "ID: 66, CreditCardType: Capital One\n",
      "ID: 67, CreditCardType: UnionPay\n",
      "ID: 68, CreditCardType: American Express\n",
      "ID: 69, CreditCardType: Chase\n",
      "ID: 70, CreditCardType: Capital One\n",
      "ID: 71, CreditCardType: Citibank\n",
      "ID: 72, CreditCardType: Citibank\n",
      "ID: 73, CreditCardType: Chase\n",
      "ID: 74, CreditCardType: American Express\n",
      "ID: 75, CreditCardType: Chase\n",
      "ID: 76, CreditCardType: Visa\n",
      "ID: 77, CreditCardType: Citibank\n",
      "ID: 78, CreditCardType: MasterCard\n",
      "ID: 79, CreditCardType: Capital One\n",
      "ID: 80, CreditCardType: Chase\n",
      "ID: 81, CreditCardType: American Express\n",
      "ID: 82, CreditCardType: Bank of America\n",
      "ID: 83, CreditCardType: Citibank\n",
      "ID: 84, CreditCardType: Capital One\n",
      "ID: 85, CreditCardType: MasterCard\n",
      "ID: 86, CreditCardType: Wells Fargo\n",
      "ID: 87, CreditCardType: Wells Fargo\n",
      "ID: 88, CreditCardType: Wells Fargo\n",
      "ID: 89, CreditCardType: Capital One\n",
      "ID: 90, CreditCardType: Maestro\n",
      "ID: 91, CreditCardType: UnionPay\n",
      "ID: 92, CreditCardType: American Express\n",
      "ID: 93, CreditCardType: Maestro\n",
      "ID: 94, CreditCardType: Wells Fargo\n",
      "ID: 95, CreditCardType: UnionPay\n",
      "ID: 96, CreditCardType: Bank of America\n",
      "ID: 97, CreditCardType: American Express\n",
      "ID: 98, CreditCardType: Chase\n",
      "ID: 99, CreditCardType: MasterCard\n",
      "ID: 100, CreditCardType: UnionPay\n",
      "ID: 101, CreditCardType: MasterCard\n",
      "ID: 102, CreditCardType: Chase\n",
      "ID: 103, CreditCardType: MasterCard\n",
      "ID: 104, CreditCardType: Chase\n",
      "ID: 105, CreditCardType: Visa\n",
      "ID: 106, CreditCardType: Discover\n",
      "ID: 107, CreditCardType: Discover\n",
      "ID: 108, CreditCardType: Citibank\n",
      "ID: 109, CreditCardType: Chase\n",
      "ID: 110, CreditCardType: Capital One\n",
      "ID: 111, CreditCardType: Discover\n",
      "ID: 112, CreditCardType: Wells Fargo\n",
      "ID: 113, CreditCardType: Capital One\n",
      "ID: 114, CreditCardType: Chase\n",
      "ID: 115, CreditCardType: Visa\n",
      "ID: 116, CreditCardType: American Express\n",
      "ID: 117, CreditCardType: Visa\n",
      "ID: 118, CreditCardType: Chase\n",
      "ID: 119, CreditCardType: Visa\n",
      "ID: 120, CreditCardType: Wells Fargo\n",
      "ID: 121, CreditCardType: Wells Fargo\n",
      "ID: 122, CreditCardType: Bank of America\n",
      "ID: 123, CreditCardType: UnionPay\n",
      "ID: 124, CreditCardType: MasterCard\n",
      "ID: 125, CreditCardType: Bank of America\n",
      "ID: 126, CreditCardType: Discover\n",
      "ID: 127, CreditCardType: Bank of America\n",
      "ID: 128, CreditCardType: Visa\n",
      "ID: 129, CreditCardType: Citibank\n",
      "ID: 130, CreditCardType: Citibank\n",
      "ID: 131, CreditCardType: Bank of America\n",
      "ID: 132, CreditCardType: Visa\n",
      "ID: 133, CreditCardType: Wells Fargo\n",
      "ID: 134, CreditCardType: Citibank\n",
      "ID: 135, CreditCardType: Citibank\n",
      "ID: 136, CreditCardType: UnionPay\n",
      "ID: 137, CreditCardType: Capital One\n",
      "ID: 138, CreditCardType: Maestro\n",
      "ID: 139, CreditCardType: UnionPay\n",
      "ID: 140, CreditCardType: Visa\n",
      "ID: 141, CreditCardType: Citibank\n",
      "ID: 142, CreditCardType: UnionPay\n",
      "ID: 143, CreditCardType: Citibank\n",
      "ID: 144, CreditCardType: Maestro\n",
      "ID: 145, CreditCardType: Bank of America\n",
      "ID: 146, CreditCardType: Bank of America\n",
      "ID: 147, CreditCardType: Chase\n",
      "ID: 148, CreditCardType: American Express\n",
      "ID: 149, CreditCardType: UnionPay\n",
      "ID: 150, CreditCardType: American Express\n",
      "ID: 151, CreditCardType: American Express\n",
      "ID: 152, CreditCardType: Citibank\n",
      "ID: 153, CreditCardType: Capital One\n",
      "ID: 154, CreditCardType: American Express\n",
      "ID: 155, CreditCardType: Discover\n",
      "ID: 156, CreditCardType: UnionPay\n",
      "ID: 157, CreditCardType: Wells Fargo\n",
      "ID: 158, CreditCardType: Visa\n",
      "ID: 159, CreditCardType: Wells Fargo\n",
      "ID: 160, CreditCardType: Visa\n",
      "ID: 161, CreditCardType: Chase\n",
      "ID: 162, CreditCardType: Capital One\n",
      "ID: 163, CreditCardType: Bank of America\n",
      "ID: 164, CreditCardType: MasterCard\n",
      "ID: 165, CreditCardType: Chase\n",
      "ID: 166, CreditCardType: Discover\n",
      "ID: 167, CreditCardType: Wells Fargo\n",
      "ID: 168, CreditCardType: MasterCard\n",
      "ID: 169, CreditCardType: American Express\n",
      "ID: 170, CreditCardType: Wells Fargo\n",
      "ID: 171, CreditCardType: Wells Fargo\n",
      "ID: 172, CreditCardType: Wells Fargo\n",
      "ID: 173, CreditCardType: MasterCard\n",
      "ID: 174, CreditCardType: Bank of America\n",
      "ID: 175, CreditCardType: Citibank\n",
      "ID: 176, CreditCardType: American Express\n",
      "ID: 177, CreditCardType: Citibank\n",
      "ID: 178, CreditCardType: Chase\n",
      "ID: 179, CreditCardType: Capital One\n",
      "ID: 180, CreditCardType: Discover\n",
      "ID: 181, CreditCardType: Citibank\n",
      "ID: 182, CreditCardType: American Express\n",
      "ID: 183, CreditCardType: Visa\n",
      "ID: 184, CreditCardType: UnionPay\n",
      "ID: 185, CreditCardType: Discover\n",
      "ID: 186, CreditCardType: Capital One\n",
      "ID: 187, CreditCardType: Maestro\n",
      "ID: 188, CreditCardType: Capital One\n",
      "ID: 189, CreditCardType: Wells Fargo\n",
      "ID: 190, CreditCardType: Visa\n",
      "ID: 191, CreditCardType: UnionPay\n",
      "ID: 192, CreditCardType: Chase\n",
      "ID: 193, CreditCardType: Capital One\n",
      "ID: 194, CreditCardType: Wells Fargo\n",
      "ID: 195, CreditCardType: Citibank\n",
      "ID: 196, CreditCardType: Capital One\n",
      "ID: 197, CreditCardType: Maestro\n",
      "ID: 198, CreditCardType: UnionPay\n",
      "ID: 199, CreditCardType: American Express\n",
      "ID: 200, CreditCardType: Discover\n",
      "\n",
      "Data after applying the filter :(American Express only) :\n",
      "\n",
      "ID: 2, CreditCardType: American Express\n",
      "ID: 12, CreditCardType: American Express\n",
      "ID: 28, CreditCardType: American Express\n",
      "ID: 39, CreditCardType: American Express\n",
      "ID: 57, CreditCardType: American Express\n",
      "ID: 62, CreditCardType: American Express\n",
      "ID: 68, CreditCardType: American Express\n",
      "ID: 74, CreditCardType: American Express\n",
      "ID: 81, CreditCardType: American Express\n",
      "ID: 92, CreditCardType: American Express\n",
      "ID: 97, CreditCardType: American Express\n",
      "ID: 116, CreditCardType: American Express\n",
      "ID: 148, CreditCardType: American Express\n",
      "ID: 150, CreditCardType: American Express\n",
      "ID: 151, CreditCardType: American Express\n",
      "ID: 154, CreditCardType: American Express\n",
      "ID: 169, CreditCardType: American Express\n",
      "ID: 176, CreditCardType: American Express\n",
      "ID: 182, CreditCardType: American Express\n",
      "ID: 199, CreditCardType: American Express\n",
      "\n",
      "Here's the data contained in the document displayed with cat\n",
      "\n",
      "ID,JobTitle,EmailAddress,FirstNameLastName,CreditCard,CreditCardType\n",
      "2,Investment  Advisor,Clint_Thorpe5003@bulaffy.com,Clint Thorpe,7083-8766-0251-2345,American Express\n",
      "12,Retail Trainee,Phillip_Carpenter9505@famism.biz,Phillip Carpenter,3657-0088-0820-5247,American Express\n",
      "28,Project Manager,Russel_Graves1378@extex.org,Russel Graves,6718-4818-8011-6024,American Express\n",
      "39,Stockbroker,Leanne_Newton1268@typill.biz,Leanne Newton,5438-0816-4166-4847,American Express\n",
      "57,Budget Analyst,Tony_Giles1960@iatim.tech,Tony Giles,8130-3425-7573-7745,American Express\n",
      "62,CNC Operator,Owen_Allcott5125@bauros.biz,Owen Allcott,4156-0107-7210-2630,American Express\n",
      "68,Project Manager,Liam_Lynn3280@kideod.biz,Liam Lynn,7152-3247-6053-2233,American Express\n",
      "74,Dentist,Regina_Woodcock5820@yahoo.com,Regina Woodcock,0208-1753-3870-8002,American Express\n",
      "81,HR Specialist,Carter_Wallace9614@atink.com,Carter Wallace,4256-7201-6717-4322,American Express\n",
      "92,Staffing Consultant,Maia_Stark2797@jiman.org,Maia Stark,3851-1403-1734-6321,American Express\n",
      "97,Stockbroker,Ciara_Lomax982@bauros.biz,Ciara Lomax,3702-3440-2472-5424,American Express\n",
      "116,Staffing Consultant,Isabel_Ellwood1475@fuliss.net,Isabel Ellwood,3738-0882-0066-6683,American Express\n",
      "148,CNC Operator,Abdul_Townend2202@infotech44.tech,Abdul Townend,4224-1226-3557-3448,American Express\n",
      "150,Fabricator,Caleb_Poulton1735@atink.com,Caleb Poulton,8203-6875-5225-0341,American Express\n",
      "151,Restaurant Manager,Ronald_Lewis6777@deavo.com,Ronald Lewis,7212-0155-5014-8471,American Express\n",
      "154,Bellman,Faith_Seymour3829@twace.org,Faith Seymour,4170-5186-6887-6558,American Express\n",
      "169,Assistant Buyer,Anthony_Hancock9083@qater.org,Anthony Hancock,0832-3357-6010-6550,American Express\n",
      "176,Healthcare Specialist,Isabella_Willson5478@nanoff.biz,Isabella Willson,5177-4868-4623-0384,American Express\n",
      "182,Pharmacist,Stephanie_Darcy3298@bauros.biz,Stephanie Darcy,0264-4020-5106-5576,American Express\n",
      "199,Investment  Advisor,Ryan_Kennedy5565@corti.com,Ryan Kennedy,3166-6287-6242-7207,American Express\n"
     ]
    }
   ],
   "source": [
    "#!wget https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json  -P data/\n",
    "\n",
    "import json # import the JSON module\n",
    "\n",
    "filename = './data/user_data.json'\n",
    "data = json.load(open(filename))\n",
    "\n",
    "# Display of ID and credit card type for each user before filtering\n",
    "print(\"\\nData before applying the filter :\\n\")\n",
    "for user in data:\n",
    "    print(f\"ID: {user['ID']}, CreditCardType: {user['CreditCardType']}\")\n",
    "\n",
    "# Data filtering for credit card type set to \"American Express\"\n",
    "filtered_data = [user for user in data if user['CreditCardType'] == 'American Express']\n",
    "\n",
    "# Display of ID and credit card type for each user after filtering\n",
    "print(\"\\nData after applying the filter :(American Express only) :\\n\")\n",
    "for user in filtered_data:\n",
    "    print(f\"ID: {user['ID']}, CreditCardType: {user['CreditCardType']}\")\n",
    "\n",
    "# Save filtered data\n",
    "pd.DataFrame(filtered_data).to_csv('filtered_data.csv', index=False)\n",
    "    \n",
    "# Document content display\n",
    "print(\"\\nHere's the data contained in the document displayed with cat\\n\")\n",
    "!cat filtered_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> DataFrame : \n",
      "   class  cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
      "0      1          5            2          4        1     6                1   \n",
      "1      0          5            2          9        1     0                1   \n",
      "2      0          0            2          8        1     3                1   \n",
      "3      1          5            3          8        1     6                1   \n",
      "4      0          5            2          3        0     5                1   \n",
      "\n",
      "   gill-spacing  gill-size  gill-color  ...  stalk-surface-below-ring  \\\n",
      "0             0          1           4  ...                         2   \n",
      "1             0          0           4  ...                         2   \n",
      "2             0          0           5  ...                         2   \n",
      "3             0          1           5  ...                         2   \n",
      "4             1          0           4  ...                         2   \n",
      "\n",
      "   stalk-color-above-ring  stalk-color-below-ring  veil-type  veil-color  \\\n",
      "0                       7                       7          0           2   \n",
      "1                       7                       7          0           2   \n",
      "2                       7                       7          0           2   \n",
      "3                       7                       7          0           2   \n",
      "4                       7                       7          0           2   \n",
      "\n",
      "   ring-number  ring-type  spore-print-color  population  habitat  \n",
      "0            1          4                  2           3        5  \n",
      "1            1          4                  3           2        1  \n",
      "2            1          4                  3           2        3  \n",
      "3            1          4                  2           3        5  \n",
      "4            1          0                  3           0        1  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "=> Average values for each class :\n",
      "       cap-shape  cap-surface  cap-color   bruises      odor  gill-attachment  \\\n",
      "class                                                                           \n",
      "0       3.266160     1.615970   4.581749  0.653992  4.334601         0.954373   \n",
      "1       3.436159     2.055158   4.421859  0.159346  3.940756         0.995403   \n",
      "\n",
      "       gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
      "class                                                    ...   \n",
      "0          0.285171   0.068441    6.622624     0.615970  ...   \n",
      "1          0.028601   0.567926    2.863636     0.514811  ...   \n",
      "\n",
      "       stalk-surface-below-ring  stalk-color-above-ring  \\\n",
      "class                                                     \n",
      "0                      1.798479                6.098859   \n",
      "1                      1.394280                5.512768   \n",
      "\n",
      "       stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
      "class                                                                          \n",
      "0                    6.064639        0.0    1.931559     1.125475   3.007605   \n",
      "1                    5.504597        0.0    2.002043     1.009193   1.522983   \n",
      "\n",
      "       spore-print-color  population   habitat  \n",
      "class                                           \n",
      "0               3.201521    3.283270  1.148289  \n",
      "1               4.021450    4.031665  1.895812  \n",
      "\n",
      "[2 rows x 22 columns]\n",
      "\n",
      "Here's the data contained in the document displayed with cat\n",
      "\n",
      "{\"0\":{\"cap-shape\":3.2661596958,\"cap-surface\":1.6159695817,\"cap-color\":4.5817490494,\"bruises\":0.6539923954,\"odor\":4.3346007605,\"gill-attachment\":0.9543726236,\"gill-spacing\":0.2851711027,\"gill-size\":0.0684410646,\"gill-color\":6.6226235741,\"stalk-shape\":0.6159695817,\"stalk-root\":1.4980988593,\"stalk-surface-above-ring\":1.7756653992,\"stalk-surface-below-ring\":1.7984790875,\"stalk-color-above-ring\":6.0988593156,\"stalk-color-below-ring\":6.0646387833,\"veil-type\":0.0,\"veil-color\":1.9315589354,\"ring-number\":1.1254752852,\"ring-type\":3.0076045627,\"spore-print-color\":3.2015209125,\"population\":3.283269962,\"habitat\":1.1482889734},\"1\":{\"cap-shape\":3.4361593463,\"cap-surface\":2.0551583248,\"cap-color\":4.4218590398,\"bruises\":0.1593462717,\"odor\":3.9407558733,\"gill-attachment\":0.9954034729,\"gill-spacing\":0.0286006129,\"gill-size\":0.5679264556,\"gill-color\":2.8636363636,\"stalk-shape\":0.5148110317,\"stalk-root\":0.6925434116,\"stalk-surface-above-ring\":1.3595505618,\"stalk-surface-below-ring\":1.3942798774,\"stalk-color-above-ring\":5.5127681307,\"stalk-color-below-ring\":5.5045965271,\"veil-type\":0.0,\"veil-color\":2.0020429009,\"ring-number\":1.0091930541,\"ring-type\":1.5229826353,\"spore-print-color\":4.0214504597,\"population\":4.0316649642,\"habitat\":1.8958120531}}"
     ]
    }
   ],
   "source": [
    "#!wget https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv  -P data/\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "filename = \"data/mushrooms_categorized.csv\"\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# a. Explore and print the DataFrame\n",
    "print(f\"=> DataFrame : \\n{df.head()}\")\n",
    "\n",
    "# b. Calculate the average value of each feature, separately for each class using groupby()\n",
    "average = df.groupby('class').mean()\n",
    "print(f\"\\n=> Average values for each class :\\n{average}\")\n",
    "\n",
    "# c. Save the file in a JSON format\n",
    "json_filename = \"mushrooms_categorized_average.json\"\n",
    "average.to_json(json_filename, orient='index')\n",
    "\n",
    "\n",
    "# Document content display\n",
    "print(\"\\nHere's the data contained in the document displayed with cat\\n\")\n",
    "!cat mushrooms_categorized_average.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading a database**\n",
    "\n",
    "Get the database `sakila.db` from the lecture `06_dataio.ipynb`, and import the table `actors` as a Pandas dataframe. Using the dataframe, count how many actors have a first name that begins with `A`.\n",
    "\n",
    "*Hint:* use the Series `.str` method to apply the Python string methods to the elements of a Series, see [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataframe with actors' first names begin with 'A' : \n",
      "    actor_id first_name    last_name          last_update\n",
      "0         29       ALEC        WAYNE  2019-02-16 18:17:33\n",
      "1         34     AUDREY      OLIVIER  2019-02-16 18:17:33\n",
      "2         49       ANNE       CRONYN  2019-02-16 18:17:33\n",
      "3         65     ANGELA       HUDSON  2019-02-16 18:17:33\n",
      "4         71       ADAM        GRANT  2019-02-16 18:17:33\n",
      "5         76   ANGELINA      ASTAIRE  2019-02-16 18:17:33\n",
      "6        125     ALBERT        NOLTE  2019-02-16 18:17:33\n",
      "7        132       ADAM       HOPPER  2019-02-16 18:17:33\n",
      "8        144     ANGELA  WITHERSPOON  2019-02-16 18:17:33\n",
      "9        146     ALBERT    JOHANSSON  2019-02-16 18:17:33\n",
      "10       165         AL      GARLAND  2019-02-16 18:17:33\n",
      "11       173       ALAN     DREYFUSS  2019-02-16 18:17:33\n",
      "12       190     AUDREY       BAILEY  2019-02-16 18:17:33\n",
      "\n",
      "Number of actors whose first name starts with 'A': 13\n"
     ]
    }
   ],
   "source": [
    "#!wget https://gist.github.com/Piyush3dB/726bf7012785d6e0fd691c3655c92654/raw/2c17ccb2eb33b3396bfa96284c53f0718a4ea62c/sakila.db -P ./data/\n",
    "\n",
    "import sqlite3 as sql # import the SQL module\n",
    "\n",
    "# Connection to the sakila.db database\n",
    "conn = sql.connect('data/sakila.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Query to select actors whose first name begins with 'A\n",
    "query = \"SELECT * FROM actor WHERE first_name LIKE 'A%'\"\n",
    "cur.execute(query)\n",
    "\n",
    "# Creating a DataFrame from results\n",
    "columns = [column[0] for column in cur.description]\n",
    "df_actors = pd.DataFrame(cur.fetchall(), columns=columns)\n",
    "\n",
    "# Closing the database connection\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"\\nDataframe with actors' first names begin with 'A' : \\n{df_actors}\")\n",
    "\n",
    "# Compter le nombre d'acteurs dont le pr√©nom commence par 'A'\n",
    "count_actors = df_actors.shape[0]\n",
    "print(f\"\\nNumber of actors whose first name starts with 'A': {count_actors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named `credit_card.dat` from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7648 5673 3775 2271\n",
      "\n",
      "3257 8247 3354 2266\n",
      "\n",
      "2722 0001 4011 6652\n",
      "\n",
      "0661 3063 3742 3150\n",
      "\n",
      "0432 1608 1462 4742\n",
      "\n",
      "5827 2027 8785 7303\n",
      "\n",
      "5774 8528 2087 1117\n",
      "\n",
      "8140 1210 6352 2845\n",
      "\n",
      "5764 1133 7301 7100\n",
      "\n",
      "6456 1737 4126 6726\n",
      "\n",
      "1228 8631 7382 0000\n",
      "\n",
      "7051 0160 5374 3166\n",
      "\n",
      "0618 3587 1630 6376\n",
      "\n",
      "1545 5454 7444 5636\n",
      "\n",
      "6735 3116 3202 6834\n",
      "\n",
      "7287 5011 1547 8413\n",
      "\n",
      "7033 2607 3328 4200\n",
      "\n",
      "2568 5244 1874 5024\n",
      "\n",
      "1684 2253 7570 7118\n",
      "\n",
      "0672 2576 0575 6631\n",
      "\n",
      "6332 8353 8787 1340\n",
      "\n",
      "1813 3361 1175 4211\n",
      "\n",
      "2477 6450 8840 2368\n",
      "\n",
      "5512 3505 2563 1326\n",
      "\n",
      "3083 7882 0621 0025\n",
      "\n",
      "4521 5148 8045 0334\n",
      "\n",
      "7563 3654 8713 5787\n",
      "\n",
      "8324 2664 0476 5561\n",
      "\n",
      "0565 2504 7168 3510\n",
      "\n",
      "5107 5507 1767 0738\n",
      "\n",
      "2462 1821 2448 1443\n",
      "\n",
      "2788 0638 6861 6554\n",
      "\n",
      "5851 5873 5474 0547\n",
      "\n",
      "0670 1004 4013 2655\n",
      "\n",
      "5874 5506 3048 0806\n",
      "\n",
      "2805 5401 8462 1260\n",
      "\n",
      "5083 8406 6310 1862\n",
      "\n",
      "1076 1445 3013 2266\n",
      "\n",
      "8440 4804 4844 5277\n",
      "\n",
      "4758 6141 0686 1387\n",
      "\n",
      "7586 0675 0315 2568\n",
      "\n",
      "2544 1258 7432 5165\n",
      "\n",
      "3474 5023 4434 5626\n",
      "\n",
      "1410 0270 0434 5086\n",
      "\n",
      "7315 4446 1104 4215\n",
      "\n",
      "0224 7742 8300 0266\n",
      "\n",
      "0170 2700 3145 0640\n",
      "\n",
      "2006 2437 8054 1600\n",
      "\n",
      "8142 4055 1776 0026\n",
      "\n",
      "3026 7380 1241 1084\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat -P ./data/\n",
    "\n",
    "credit_card_numbers = []\n",
    "\n",
    "with open('data/credit_card.dat', 'rb') as file: # Open file in binary read mode\n",
    "    for line in file: # Read each line of the file\n",
    "\n",
    "        # Cut the binary data into 6-bit pieces, and ignoring the last 4 bits, which are padding\n",
    "        numbers = [line[i:i+6] for i in range(0, len(line) - 4, 6)]\n",
    "        # Convert each 6-bit pieces to its decimal representation, then to the corresponding character\n",
    "        credit_card_number = ''.join([chr(int(num, 2)) for num in numbers])\n",
    "        credit_card_numbers.append(credit_card_number)\n",
    "\n",
    "with open('data/credit_card_numbers.txt', 'w') as output_file: # Write the credit card numbers to a new file\n",
    "    for number in credit_card_numbers:\n",
    "        output_file.write(number + '\\n')\n",
    "\n",
    "!cat data/credit_card_numbers.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image\n",
    "#Image(\"images/data_format.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/ga9wi6b40cakgae/data_000637.txt -P data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, \"pack\" the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_dataio.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.\n",
    "\n",
    "import struct\n",
    "\n",
    "df = pd.read_csv('data/data_000637.txt')\n",
    "\n",
    "with open('data/output_binary_file.bin', 'wb') as binary_file:\n",
    "    for i in range(len(df)): \n",
    "        row = df.iloc[i]\n",
    "        head, fpga, tdc_chan, orb_cnt, bx, tdc_meas = row\n",
    "\n",
    "        # Pack the values into a 64-bit word\n",
    "        word = (\n",
    "            ((head & 0x3) << 62) |\n",
    "            ((fpga & 0xF) << 58) |\n",
    "            ((tdc_chan & 0x1FF) << 49) |\n",
    "            ((orb_cnt & 0xFFFFFFFF) << 17) |\n",
    "            ((bx & 0xFFF) << 5) |\n",
    "            (tdc_meas & 0x1F)\n",
    "        )\n",
    "\n",
    "        # Write the 64-bit word to the binary file\n",
    "        binary_file.write(struct.pack('<q', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "View the first 10 lines after unpacking : \n",
      "    HEAD  FPGA  CHANNEL   ORBIT_CNT  BX_CNT  TDC_MEAS\n",
      "1      1     0      123  3869200167    2374        26\n",
      "2      1     0      124  3869200167    2374        27\n",
      "3      1     0       63  3869200167    2553        28\n",
      "4      1     0       64  3869200167    2558        19\n",
      "5      1     0       64  3869200167    2760        25\n",
      "6      1     0       63  3869200167    2762         4\n",
      "7      1     0       61  3869200167    2772        14\n",
      "8      1     0      139  3869200167    2776         0\n",
      "9      1     0       62  3869200167    2774        21\n",
      "10     1     0       60  3869200167    2788         7\n"
     ]
    }
   ],
   "source": [
    "# b.\n",
    "\n",
    "data = {}\n",
    "\n",
    "with open('data/output_binary_file.bin', 'rb') as file:\n",
    "    file_content = file.read()\n",
    "    word_counter = 0\n",
    "    word_size = 8\n",
    "    for i in range(0, len(file_content), word_size):\n",
    "        word_counter += 1\n",
    "        word = struct.unpack('<q', file_content[i : i + word_size])[0]  \n",
    "        head     = (word >> 62) & 0x3\n",
    "        fpga     = (word >> 58) & 0xF\n",
    "        tdc_chan = (word >> 49) & 0x1FF\n",
    "        orb_cnt  = (word >> 17) & 0xFFFFFFFF\n",
    "        bx       = (word >> 5 ) & 0xFFF\n",
    "        tdc_meas = (word >> 0 ) & 0x1F\n",
    "\n",
    "        entry = {\n",
    "            'HEAD': head, \n",
    "            'FPGA': fpga, \n",
    "            'CHANNEL': tdc_chan, \n",
    "            'ORBIT_CNT': orb_cnt, \n",
    "            'BX_CNT': bx, \n",
    "            'TDC_MEAS': tdc_meas\n",
    "        }\n",
    "        data[word_counter] = entry\n",
    "        \n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "print(f\"\\nView the first 10 lines after unpacking : \\n{df.head(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Size of output_binary_file.bin : 10485760 bytes\n",
      "Size of data_000637.txt : 33179236 bytes\n",
      "\n",
      "The difference in size on disk between the text file (data_000637.txt) and the binary file (output_binary_file.bin) is approximately 22693476 bytes. This indicates that the binary file is significantly smaller than the equivalent text file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# c.\n",
    "\n",
    "import os \n",
    "\n",
    "txt_file = os.path.getsize('./data/data_000637.txt')\n",
    "bin_file = os.path.getsize('./data/output_binary_file.bin')\n",
    "\n",
    "# Size of output_binary_file.bin : 10,5 MB\n",
    "# Size of data_000637.txt : 33,2 MB\n",
    "\n",
    "# The difference in size on disk between the text file (data_000637.txt) and the binary file (output_binary_file.bin) is approximately 22.7 MB. This indicates that the binary file is significantly smaller than the equivalent text file.\n",
    "\n",
    "print(f\"\"\"\n",
    "Size of output_binary_file.bin : {bin_file} bytes\n",
    "Size of data_000637.txt : {txt_file} bytes\n",
    "\n",
    "The difference in size on disk between the text file (data_000637.txt) and the binary file (output_binary_file.bin) is approximately {txt_file - bin_file} bytes. This indicates that the binary file is significantly smaller than the equivalent text file.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
