{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3dec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors match: False\n",
      "Eigenvalues match: False\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1000,3) and (2,1000) not aligned: 3 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m num_components_99 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(explained_variance_ratio \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Perform PCA\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m pca_result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(data \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), u_svd[:, :num_components_99]\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Plot the original and new basis\u001b[39;00m\n\u001b[0;32m     44\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1000,3) and (2,1000) not aligned: 3 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "#ex1\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "N = 1000\n",
    "u = [0, 0, 0]\n",
    "o = [1, 3, 0]\n",
    "\n",
    "x1 = np.random.normal(u[0], o[0], N)\n",
    "x2 = x1 + np.random.normal(u[1], o[1], N)\n",
    "x3 = 2 * x1 + x2\n",
    "\n",
    "data = np.column_stack((x1, x2, x3))\n",
    "\n",
    "cov_matrix = np.cov(data, rowvar=False)\n",
    "\n",
    "eigenvalues_cov, eigenvectors_cov = np.linalg.eig(cov_matrix)\n",
    "\n",
    "u_svd, s_svd, vt_svd = np.linalg.svd(data - np.mean(data, axis=0))\n",
    "\n",
    "print(\"Eigenvectors match:\", np.allclose(np.abs(eigenvectors_cov), np.abs(vt_svd.T[:, :3])))\n",
    "print(\"Eigenvalues match:\", np.allclose(eigenvalues_cov, s_svd ** 2 / (N - 1)))\n",
    "\n",
    "explained_variance_ratio = np.cumsum(s_svd ** 2) / np.sum(s_svd ** 2)\n",
    "\n",
    "num_components_99 = np.argmax(explained_variance_ratio >= 0.99) + 1\n",
    "\n",
    "pca_result = np.dot(data - np.mean(data, axis=0), u_svd[:, :num_components_99].T)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "axs[0, 0].scatter(data[:, 0], data[:, 1], alpha=0.5)\n",
    "axs[0, 1].scatter(data[:, 0], data[:, 2], alpha=0.5)\n",
    "axs[0, 2].scatter(data[:, 1], data[:, 2], alpha=0.5)\n",
    "\n",
    "axs[1, 0].scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.5)\n",
    "axs[1, 1].scatter(pca_result[:, 0], pca_result[:, 2], alpha=0.5)\n",
    "axs[1, 2].scatter(pca_result[:, 1], pca_result[:, 2], alpha=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a5f161b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvectors match: False\n",
      "Eigenvalues match: False\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1000,13) and (1000,2) not aligned: 13 (dim 1) != 1000 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m num_components_99_with_noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(explained_variance_ratio_with_noise \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Perform PCA on the dataset with noise\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m pca_result_with_noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(data_with_noise \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(data_with_noise, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), u_svd_with_noise[:, :num_components_99_with_noise])\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Plot the original and new basis\u001b[39;00m\n\u001b[0;32m     52\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1000,13) and (1000,2) not aligned: 13 (dim 1) != 1000 (dim 0)"
     ]
    }
   ],
   "source": [
    "#ex2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "N = 1000\n",
    "u = [0, 0, 0]\n",
    "o = [1, 3, 0]\n",
    "\n",
    "x1 = np.random.normal(u[0], o[0], N)\n",
    "x2 = x1 + np.random.normal(u[1], o[1], N)\n",
    "x3 = 2 * x1 + x2\n",
    "\n",
    "data_original = np.column_stack((x1, x2, x3))\n",
    "\n",
    "num_noise_variables = 10\n",
    "noise_std = 0.05  # A smaller standard deviation for noise\n",
    "\n",
    "noise = np.random.normal(0, noise_std, size=(N, num_noise_variables))\n",
    "\n",
    "data_with_noise = np.column_stack((data_original, noise))\n",
    "\n",
    "cov_matrix_with_noise = np.cov(data_with_noise, rowvar=False)\n",
    "\n",
    "eigenvalues_with_noise, eigenvectors_with_noise = np.linalg.eig(cov_matrix_with_noise)\n",
    "\n",
    "u_svd_with_noise, s_svd_with_noise, vt_svd_with_noise = np.linalg.svd(data_with_noise - np.mean(data_with_noise, axis=0))\n",
    "\n",
    "print(\"Eigenvectors match:\", np.allclose(np.abs(eigenvectors_with_noise), np.abs(vt_svd_with_noise.T)))\n",
    "print(\"Eigenvalues match:\", np.allclose(eigenvalues_with_noise, s_svd_with_noise ** 2 / (N - 1)))\n",
    "\n",
    "explained_variance_ratio_with_noise = np.cumsum(s_svd_with_noise ** 2) / np.sum(s_svd_with_noise ** 2)\n",
    "\n",
    "num_components_99_with_noise = np.argmax(explained_variance_ratio_with_noise >= 0.99) + 1\n",
    "\n",
    "pca_result_with_noise = np.dot(data_with_noise - np.mean(data_with_noise, axis=0), u_svd_with_noise[:, :num_components_99_with_noise])\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Original Basis\n",
    "axs[0, 0].scatter(data_original[:, 0], data_original[:, 1], alpha=0.5)\n",
    "axs[0, 1].scatter(data_original[:, 0], data_original[:, 2], alpha=0.5)\n",
    "axs[0, 2].scatter(data_original[:, 1], data_original[:, 2], alpha=0.5)\n",
    "axs[0, 0].set_title(\"Original Basis\")\n",
    "\n",
    "# New Basis with Noise\n",
    "axs[1, 0].scatter(pca_result_with_noise[:, 0], pca_result_with_noise[:, 1], alpha=0.5)\n",
    "axs[1, 1].scatter(pca_result_with_noise[:, 0], pca_result_with_noise[:, 2], alpha=0.5)\n",
    "axs[1, 2].scatter(pca_result_with_noise[:, 1], pca_result_with_noise[:, 2], alpha=0.5)\n",
    "axs[1, 0].set_title(\"New Basis with Noise\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('data/magic04.data', header=None)\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "X_standardized = StandardScaler().fit_transform(X)\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_standardized)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "plt.plot(np.cumsum(explained_variance_ratio))\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance Ratio')\n",
    "plt.show()\n",
    "\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "num_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "\n",
    "pca = PCA(n_components=num_components)\n",
    "X_pca = pca.fit_transform(X_standardized)\n",
    "\n",
    "columns = [f'PC{i}' for i in range(1, num_components + 1)]\n",
    "df_pca = pd.DataFrame(data=X_pca, columns=columns)\n",
    "df_final = pd.concat([df_pca, y], axis=1)\n",
    "\n",
    "print(df_final.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
